# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-uOJHc0gekbQKymEiOxO3ftV-6ZApMs

HOUSE PRICE PREDICTION
"""

#importing libraries
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib
matplotlib.rcParams["figure.figsize"] = (20,10)

"""# Data loading"""

#Reading the csv file
df1 = pd.read_csv("Bengaluru_House_Data.csv")
df1.head()

#Checking the shape of the original dataset
df1.shape

df1.groupby('area_type')['area_type'].agg('count')

#Dropping out the unnecessary parameters
df2 = df1.drop(['area_type', 'society', 'balcony', 'availability'], axis = 'columns')
df2.head()

"""# Data cleaning"""

#Checking the values with null
df2.isnull().sum()

#Dropping the values which are null
df3 = df2.dropna()
df3.head()

df3.shape

df3['size'].unique()

df3['bhk'] = df3['size'].apply(lambda x : int(x.split(' ')[0]))

df3.head()

df3[df3.bhk>20]

df3.total_sqft.unique()

#For getting the values which are not in float
def is_float(x):
    try:
        float(x)
    except:
        return False
    return True

df3[~df3['total_sqft'].apply(is_float)].head(10)

#Getting the mean values which are present in range(For example 2100-2850)
def convert_sqft_to_num(x):
    tokens = x.split('-')
    if len(tokens) == 2:
        return (float(tokens[0]) + float(tokens[1])) / 2
    try:
        return float(x)
    except:
        return None

df4 = df3.copy()
df4['total_sqft'] = df4['total_sqft'].apply(convert_sqft_to_num)
df4.head(3)

#Getting a new coloumn ('price per square fit')
df5 = df4.copy()
df5['price_per_sqft'] = df5['price'] * 100000 / df5['total_sqft']

len(df5.location.unique())

#Grouping data with respect to location
df5.location = df5.location.apply(lambda x : x.strip())

location_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending = False)
location_stats

"""# Dimensionality Reduction
Any location having less than 10 data points should be tagged as "other" location. This way number of categories can be reduced by huge amount. Later on when we do one hot encoding, it will help us with having fewer dummy columns
"""

#Getting the number of loations with less than equal to 10 examples
len(location_stats[location_stats<=10])

#Displaying the locations with less examples
location_stats_less_than_10 = location_stats[location_stats<=10]
location_stats_less_than_10

#Getting the number of unique location
len(df5.location.unique())

df5.location = df5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)
len(df5.location.unique())

df5.head(10)

"""
# Outlier Removal Using Business Logic
As a data scientist when you have a conversation with your business manager (who has expertise in real estate), he will tell you that normally square ft per bedroom is 300 (i.e. 2 bhk apartment is minimum 600 sqft. If you have for example 400 sqft apartment with 2 bhk than that seems suspicious and can be removed as an outlier. We will remove such outliers by keeping our minimum thresold per bhk to be 300 sqft"""

df5[df5.total_sqft/df5.bhk<300].head()

df5.shape

#Removing the outliers
df6 = df5[~(df5.total_sqft/df5.bhk<300)]
df6.shape

"""# Outlier Removal Using Standard Deviation and Mean"""

df6.price_per_sqft.describe()

"""
Here we find that min price per sqft is 267 rs/sqft whereas max is 12000000, this shows a wide variation in property prices. We should remove outliers per location using mean and one standard deviation"""

def remove_pps_outliers(df):
    df_out = pd.DataFrame()
    for key, subdf in df.groupby('location'):
        m = np.mean(subdf.price_per_sqft)
        st = np.std(subdf.price_per_sqft)
        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]
        df_out = pd.concat([df_out,reduced_df],ignore_index=True)
    return df_out
df7 = remove_pps_outliers(df6)
df7.shape

"""
Let's check if for a given location how does the 2 BHK and 3 BHK property prices look like"""

def plot_scatter_chart(df,location):
    bhk2 = df[(df.location==location) & (df.bhk==2)]
    bhk3 = df[(df.location==location) & (df.bhk==3)]
    matplotlib.rcParams['figure.figsize'] = (15,10)
    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)
    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)
    plt.xlabel("Total Square Feet Area")
    plt.ylabel("Price (Lakh Indian Rupees)")
    plt.title(location)
    plt.legend()

plot_scatter_chart(df7,"Rajaji Nagar")

"""
We should also remove properties where for same location, the price of (for example) 3 bedroom apartment is less than 2 bedroom apartment (with same square ft area). What we will do is for a given location, we will build a dictionary of stats per bhk, i.e.

{
    '1' : {
        'mean': 4000,
        'std: 2000,
        'count': 34
    },
    '2' : {
        'mean': 4300,
        'std: 2300,
        'count': 22
    },    
}
Now we can remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft of 1 BHK apartment"""

def remove_bhk_outliers(df):
    exclude_indices = np.array([])
    for location, location_df in df.groupby('location'):
        bhk_stats = {}
        for bhk, bhk_df in location_df.groupby('bhk'):
            bhk_stats[bhk] = {
                'mean': np.mean(bhk_df.price_per_sqft),
                'std': np.std(bhk_df.price_per_sqft),
                'count': bhk_df.shape[0]
            }
        for bhk, bhk_df in location_df.groupby('bhk'):
            stats = bhk_stats.get(bhk-1)
            if stats and stats['count']>5:
                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)
    return df.drop(exclude_indices,axis='index')
df8 = remove_bhk_outliers(df7)
# df8 = df7.copy()
df8.shape

#Plot same scatter chart again to visualize price_per_sqft for 2 BHK and 3 BHK properties
plot_scatter_chart(df8,"Rajaji Nagar")

plot_scatter_chart(df8, "Hebbal")

import matplotlib
matplotlib.rcParams["figure.figsize"] = (20,10)
plt.hist(df8.price_per_sqft,rwidth=0.8)
plt.xlabel("Price Per Square Feet")
plt.ylabel("Count")

"""# Outlier Removal Using Bathrooms Feature"""

df8.bath.unique()

plt.hist(df8.bath,rwidth=0.8)
plt.xlabel("Number of bathrooms")
plt.ylabel("Count")

df8[df8.bath>10]

"""It is unusual to have 2 more bathrooms than number of bedrooms in a home"""

df8[df8.bath>df8.bhk+2]

"""if you have 4 bedroom home and even if you have bathroom in all 4 rooms plus one guest bathroom, you will have total bath = total bed + 1 max. Anything above that is an outlier or a data error and can be removed"""

df9 = df8[df8.bath<df8.bhk+2]
df9.shape

df9.head(2)

df10 = df9.drop(['size','price_per_sqft'],axis='columns')
df10.head(3)

"""# Use One Hot Encoding For Location"""

dummies = pd.get_dummies(df10.location)
dummies.head(3)

df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')
df11.head()

df12 = df11.drop('location',axis='columns')
df12.head(2)

"""## Build the model"""

df12.shape

X = df12.drop(['price'],axis='columns')
X.head(3)

X.shape

y = df12.price
y.head(3)

len(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)

from sklearn.linear_model import LinearRegression
lr_clf = LinearRegression()
lr_clf.fit(X_train,y_train)
lr_clf.score(X_test,y_test)

"""# Use K Fold cross validation to measure accuracy of our Linear Regression model"""

from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_val_score

cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

cross_val_score(LinearRegression(), X, y, cv=cv)

"""We can see that in 5 iterations we get a score above 80% all the time. This is pretty good but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV for this purpose

# Find best model using GridSearchCV
"""

import pandas as pd
from sklearn.model_selection import GridSearchCV, ShuffleSplit
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.tree import DecisionTreeRegressor

def find_best_model_using_gridsearchcv(X, y):
    algos = {
        'linear_regression': {
            'model': LinearRegression(),
            'params': {
                # Removed 'normalize' parameter as it's not valid in recent versions
                'fit_intercept': [True, False]
            }
        },
        'lasso': {
            'model': Lasso(),
            'params': {
                'alpha': [1, 2],
                'selection': ['random', 'cyclic']
            }
        },
        'decision_tree': {
            'model': DecisionTreeRegressor(),
            'params': {
                'criterion': ['squared_error', 'friedman_mse'],  # Updated criteria to recent version names
                'splitter': ['best', 'random']
            }
        }
    }

    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

    for algo_name, config in algos.items():
        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(X, y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])

# Example usage
# Assuming X and y are already defined
# X, y = ... (your feature matrix and target variable)
# result = find_best_model_using_gridsearchcv(X, y)
# print(result)

"""Based on above results we can say that LinearRegression gives the best score. Hence we will use that.

# Test the model for few properties
"""

def predict_price(location,sqft,bath,bhk):
    loc_index = np.where(X.columns==location)[0][0]

    x = np.zeros(len(X.columns))
    x[0] = sqft
    x[1] = bath
    x[2] = bhk
    if loc_index >= 0:
        x[loc_index] = 1

    return lr_clf.predict([x])[0]

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder

# Create a simple dummy dataset
data = {
    'location': ['1st Phase JP Nagar', '2nd Phase JP Nagar', '1st Phase JP Nagar', '3rd Phase JP Nagar'],
    'sqft': [1000, 1500, 1200, 800],
    'bath': [2, 3, 2, 1],
    'bhk': [2, 3, 2, 1],
    'price': [50, 80, 60, 40]
}
df = pd.DataFrame(data)

# Encode the location column
location_encoder = LabelEncoder()
df['location_encoded'] = location_encoder.fit_transform(df['location'])

# Define feature columns and target
X = df[['location_encoded', 'sqft', 'bath', 'bhk']]
y = df['price']

# Train a simple linear regression model
model = LinearRegression()
model.fit(X, y)

# Function to predict price
def predict_price(location, sqft, bath, bhk):
    # Encode the location
    loc_index = location_encoder.transform([location])[0]

    # Create an input array
    x = np.array([loc_index, sqft, bath, bhk]).reshape(1, -1)

    # Predict the price
    predicted_price = model.predict(x)[0]

    return predicted_price

# Usage Example
predicted_price = predict_price('1st Phase JP Nagar', 1000, 2, 2)
print(f"The predicted price is: {predicted_price}")

predict_price('1st Phase JP Nagar',1000, 3, 3)

predict_price('2nd Phase JP Nagar',1500, 2, 2)

predict_price('1st Phase JP Nagar',1200, 2, 2)